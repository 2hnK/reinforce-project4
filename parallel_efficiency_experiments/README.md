# ë³‘ë ¬í™” íš¨ìœ¨ì„± ì‹¤í—˜ (Parallel Efficiency Experiments)

Ray RLlib PPOì˜ ë³‘ë ¬í™” ì„¤ì •ì´ í•™ìŠµ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.

## ðŸ“ ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
parallel_efficiency_experiments/
â”œâ”€â”€ README.md                              # ì´ íŒŒì¼
â”œâ”€â”€ EXPERIMENT_ANALYSIS.md                 # ìƒì„¸í•œ ì‹¤í—˜ ë¶„ì„ ë° ìž¬ì‹¤í—˜ ì œì•ˆ
â”œâ”€â”€ GPU_MEASUREMENT_GUIDE.md               # GPU ì¸¡ì • ê°€ì´ë“œ
â”‚
â”œâ”€â”€ parallel_efficiency_experiment.py      # ì›ë³¸ ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸ (12ê°œ êµ¬ì„±)
â”œâ”€â”€ parallel_experiment_runners_only.py    # ìž¬ì‹¤í—˜ ìŠ¤í¬ë¦½íŠ¸ (ëŸ¬ë„ˆë§Œ ë³€ê²½)
â”‚
â”œâ”€â”€ analyze_parallel_efficiency_simple.py  # ì›ë³¸ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ analyze_runners_only.py                # ëŸ¬ë„ˆ ì „ìš© ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
â”‚
â”œâ”€â”€ results/                               # ì‹¤í—˜ ê²°ê³¼ íŒŒì¼ë“¤
â”‚   â”œâ”€â”€ parallel_experiments_final.json    # ì›ë³¸ ì‹¤í—˜ ê²°ê³¼
â”‚   â”œâ”€â”€ parallel_experiments_progress.json
â”‚   â”œâ”€â”€ parallel_efficiency_dashboard.png  # ì‹œê°í™”
â”‚   â”œâ”€â”€ parallel_efficiency_report.txt     # í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸
â”‚   â”œâ”€â”€ runners_only_final.json            # ìž¬ì‹¤í—˜ ê²°ê³¼ (ìƒì„± ì˜ˆì •)
â”‚   â””â”€â”€ runners_only_dashboard.png         # ìž¬ì‹¤í—˜ ì‹œê°í™” (ìƒì„± ì˜ˆì •)
â”‚
â””â”€â”€ archive/                               # ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” íŒŒì¼ë“¤
    â”œâ”€â”€ experiment_utils.py
    â”œâ”€â”€ analyze_gpu_efficiency.py
    â””â”€â”€ parallel_efficiency.md
```

## ðŸŽ¯ ì‹¤í—˜ ëª©ì 

Ray RLlibì˜ ì£¼ìš” ë³‘ë ¬í™” íŒŒë¼ë¯¸í„°ê°€ í•™ìŠµ ì†ë„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ë¶„ì„:
- `num_env_runners`: í™˜ê²½ ìƒ˜í”Œë§ì„ ìˆ˜í–‰í•˜ëŠ” ì›Œì»¤ ìˆ˜
- `num_envs_per_env_runner`: ê° ì›Œì»¤ê°€ ì‹¤í–‰í•˜ëŠ” í™˜ê²½ ì¸ìŠ¤í„´ìŠ¤ ìˆ˜

## ðŸ“Š ì£¼ìš” ë°œê²¬ (ì›ë³¸ ì‹¤í—˜)

### ì‹¤í—˜ 1: 12ê°œ êµ¬ì„± í…ŒìŠ¤íŠ¸

**ì‹¤í–‰ ë‚ ì§œ**: 2025-11-04  
**í™˜ê²½**: HalfCheetah-v5 (MuJoCo)  
**ì‹œìŠ¤í…œ**: i7-12700 (16 logical cores), 32GB RAM, RTX 3070 8GB

#### ê²°ê³¼ ìš”ì•½

| Config | Total Envs | Speedup | Efficiency | ì¶”ì²œ |
|--------|-----------|---------|-----------|------|
| 2rÃ—1e  | 2         | 1.72Ã—   | 86.2%     | â­â­â­ ìµœê³  íš¨ìœ¨ |
| 4rÃ—1e  | 4         | 2.68Ã—   | 67.0%     | â­â­ ê· í˜•ìž¡ížŒ ì„ íƒ |
| 8rÃ—1e  | 8         | 4.12Ã—   | 51.5%     | â­ ì—¬ì „ížˆ ì–‘í˜¸ |
| 8rÃ—2e  | 16        | 5.76Ã—   | 36.0%     | âŒ ë¹„íš¨ìœ¨ì  |

#### í•µì‹¬ ì¸ì‚¬ì´íŠ¸

1. **ëŸ¬ë„ˆ ì¦ê°€ > í™˜ê²½ ì¦ê°€**
   - `2rÃ—1e` (86.2%) > `1rÃ—2e` (78.4%)
   - ëŸ¬ë„ˆ ë³‘ë ¬í™”ê°€ ë” íš¨ìœ¨ì 

2. **í™•ìž¥ì„± í•œê³„**
   - 8 envsê¹Œì§€ëŠ” 50%+ íš¨ìœ¨ì„± ìœ ì§€
   - 16 envsì—ì„œëŠ” 35-36%ë¡œ ê¸‰ê²©ížˆ ê°ì†Œ

3. **GPU í™œìš© ë¶ˆê°€**
   - MuJoCoëŠ” CPU ì‹œë®¬ë ˆì´ì…˜
   - GPU ì‚¬ìš©ë¥  0-5% (ê±°ì˜ ë¯¸ì‚¬ìš©)

### ë¬¸ì œì  ë° í•œê³„

âŒ **í˜„ìž¬ ì‹¤í—˜ì˜ í•œê³„**:
- env_runners vs envs_per_runner ë¹„êµê°€ ë¶ˆëª…í™•
- GPU ì¸¡ì •ì´ ì˜ë¯¸ ì—†ìŒ (MuJoCoëŠ” CPU ê¸°ë°˜)
- í™•ìž¥ì„± í•œê³„ì˜ ì›ì¸ ë¶ˆëª…í™•
- ë³€ìˆ˜ê°€ 2ê°œë¼ì„œ ì¸ê³¼ê´€ê³„ íŒŒì•… ì–´ë ¤ì›€

âœ… **ê°œì„  ë°©ì•ˆ** â†’ `EXPERIMENT_ANALYSIS.md` ì°¸ì¡°

## ðŸš€ ë¹ ë¥¸ ì‹œìž‘

### 1. ì›ë³¸ ì‹¤í—˜ ê²°ê³¼ ë¶„ì„

```bash
cd parallel_efficiency_experiments
python analyze_parallel_efficiency_simple.py
```

**ì¶œë ¥**:
- `results/parallel_efficiency_dashboard.png`: 3-5ê°œ ì°¨íŠ¸ (GPU í¬í•¨ ì—¬ë¶€ì— ë”°ë¼ ë‹¤ë¦„)
- `results/parallel_efficiency_report.txt`: í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸

### 2. ìž¬ì‹¤í—˜ ì‹¤í–‰ (ê¶Œìž¥)

**ëª©ì **: ëŸ¬ë„ˆ ìˆ˜ë§Œ ë³€ê²½í•˜ì—¬ ìˆœìˆ˜ ë³‘ë ¬í™” íš¨ê³¼ ì¸¡ì •

```bash
# ê¸°ë³¸ ì‹¤í–‰ (1,2,3,4,6,8,12,16 ëŸ¬ë„ˆ)
python parallel_experiment_runners_only.py

# ì»¤ìŠ¤í…€ ëŸ¬ë„ˆ ìˆ˜
python parallel_experiment_runners_only.py --runners "1,2,4,8,16"

# ë°˜ë³µ íšŸìˆ˜ ì¡°ì •
python parallel_experiment_runners_only.py --iterations 10
```

**ê²°ê³¼ ë¶„ì„**:
```bash
python analyze_runners_only.py
```

## ðŸ“ˆ ì£¼ìš” ë©”íŠ¸ë¦­

### ì¸¡ì • í•­ëª©

1. **time_this_iter_s**: ê° iteration ì†Œìš” ì‹œê°„
2. **SPS** (Steps Per Second): ìƒ˜í”Œ ì²˜ë¦¬ëŸ‰
3. **Speedup**: ê¸°ì¤€ì„  ëŒ€ë¹„ ì†ë„ í–¥ìƒ (baseline_time / current_time)
4. **Efficiency**: ë³‘ë ¬ íš¨ìœ¨ì„± (speedup / total_envs Ã— 100%)

### í‰ê°€ ê¸°ì¤€

- **Excellent**: Efficiency > 70%
- **Good**: Efficiency 60-70%
- **Acceptable**: Efficiency 50-60%
- **Poor**: Efficiency < 50%

## ðŸ”§ ì‹¤í—˜ êµ¬ì„±

### í•˜ë“œì›¨ì–´ ì‚¬ì–‘

- **CPU**: Intel i7-12700 (8P+4E cores, 16 logical)
- **RAM**: 32GB (ì»¨í…Œì´ë„ˆì—ì„œ 15.54GB ì‚¬ìš© ê°€ëŠ¥)
- **GPU**: NVIDIA RTX 3070 8GB VRAM

### PPO ì„¤ì •

```python
config = (
    PPOConfig()
    .environment("HalfCheetah-v5")
    .training(
        lambda_=0.95,
        lr=0.0003,
        num_epochs=3,
        train_batch_size=16384,
        minibatch_size=4096,
    )
    .env_runners(
        num_env_runners=N,  # ë³€ê²½ë˜ëŠ” íŒŒë¼ë¯¸í„°
        num_envs_per_env_runner=M,  # ë³€ê²½ë˜ëŠ” íŒŒë¼ë¯¸í„°
    )
)
```

## ðŸ“ ìž¬ì‹¤í—˜ ì œì•ˆ

ìƒì„¸í•œ ë¶„ì„ì€ `EXPERIMENT_ANALYSIS.md` ì°¸ì¡°

### ì˜µì…˜ A: ëŸ¬ë„ˆë§Œ ì¸¡ì • (â­â­ ìµœì¶”ì²œ)

**ëª©ì **: ë³€ìˆ˜ 1ê°œë§Œ ë³€ê²½í•˜ì—¬ ëª…í™•í•œ ì¸ê³¼ê´€ê³„ íŒŒì•…

```bash
python parallel_experiment_runners_only.py
```

**ìž¥ì **:
- ê²°ê³¼ í•´ì„ ê°„ë‹¨
- ì‹¤í—˜ ì‹œê°„ ë‹¨ì¶•
- ì‹¤ìš©ì  ê°€ì¹˜ ë†’ìŒ

### ì˜µì…˜ B: GPU í™œìš© ê·¹ëŒ€í™”

**ëª©ì **: GPUë¥¼ ì‹¤ì œë¡œ ì‚¬ìš©í•˜ëŠ” êµ¬ì„± í…ŒìŠ¤íŠ¸

**ë³€ê²½ ì‚¬í•­**:
- `num_epochs`: 3 â†’ 20
- `train_batch_size`: 16384 â†’ 65536
- ì‹ ê²½ë§ í¬ê¸° ì¦ê°€
- `num_learners`: 0 â†’ 1

### ì˜µì…˜ C: ì„¸ë°€í•œ ì¸¡ì •

**ëª©ì **: ë¬¼ë¦¬ ì½”ì–´ vs ë…¼ë¦¬ ì½”ì–´ ì°¨ì´ í™•ì¸

**í…ŒìŠ¤íŠ¸**: 1, 2, 3, 4, 6, 8, 12, 16 ëŸ¬ë„ˆ

## ðŸŽ“ í•™ìŠµ ìžë£Œ

### ê´€ë ¨ ë¬¸ì„œ

- `EXPERIMENT_ANALYSIS.md`: ìƒì„¸ ë¶„ì„ + ìž¬ì‹¤í—˜ ì œì•ˆ
- `GPU_MEASUREMENT_GUIDE.md`: GPU ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë°©ë²•

### í•µì‹¬ ê°œë…

**Strong Scaling**: ìž‘ì—…ëŸ‰ ê³ ì •, í”„ë¡œì„¸ì„œ ì¦ê°€  
â†’ ì´ìƒì ìœ¼ë¡œëŠ” Në°° í”„ë¡œì„¸ì„œ = Në°° ì†ë„

**Parallel Efficiency**: ì‹¤ì œ speedup / ì´ë¡ ì  speedup  
â†’ ì˜¤ë²„í—¤ë“œê°€ ì ì„ìˆ˜ë¡ 100%ì— ê°€ê¹Œì›€

**Amdahl's Law**: ë³‘ë ¬í™” ê°€ëŠ¥í•œ ë¶€ë¶„ë§Œ ê°€ì†  
â†’ ì§ë ¬ ë¶€ë¶„(í†µì‹ , ë™ê¸°í™”)ì´ bottleneck

## ðŸ” íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### GPU ì‚¬ìš©ë¥ ì´ ë‚®ìŒ

**ì›ì¸**: MuJoCoëŠ” CPU ì‹œë®¬ë ˆì´ì…˜  
**í•´ê²°**: ì •ìƒ - GPUëŠ” ì‹ ê²½ë§ í•™ìŠµì—ë§Œ ì‚¬ìš©ë¨

### íš¨ìœ¨ì„±ì´ ë‚®ìŒ (< 50%)

**ì›ì¸**: 
- í†µì‹  ì˜¤ë²„í—¤ë“œ
- ë™ê¸°í™” ëŒ€ê¸° ì‹œê°„
- ìºì‹œ ê²½í•©

**í•´ê²°**:
- ëŸ¬ë„ˆ ìˆ˜ ì¤„ì´ê¸°
- ë°°ì¹˜ í¬ê¸° ëŠ˜ë¦¬ê¸°
- ë” ê¸´ ì—í”¼ì†Œë“œ ì‚¬ìš©

### ì‹¤í—˜ì´ ì‹¤íŒ¨í•¨

**ë””ë²„ê¹…**:
```bash
# ì§„í–‰ ìƒí™© í™•ì¸
tail -f results/parallel_experiments_progress.json

# ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ í™•ì¸
htop  # CPU/RAM
nvidia-smi  # GPU
```

## ðŸ“š ì°¸ê³  ìžë£Œ

- [Ray RLlib ê³µì‹ ë¬¸ì„œ](https://docs.ray.io/en/latest/rllib/)
- [Parallel Training Guide](https://docs.ray.io/en/latest/rllib/rllib-training.html#scaling-guide)
- [PPO Algorithm](https://docs.ray.io/en/latest/rllib/rllib-algorithms.html#ppo)

## ðŸ¤ ê¸°ì—¬

ì‹¤í—˜ ê²°ê³¼ë‚˜ ê°œì„  ì‚¬í•­ì´ ìžˆë‹¤ë©´ ì´ìŠˆë¥¼ ì—´ì–´ì£¼ì„¸ìš”!
